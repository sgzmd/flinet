{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:23:10.925909100Z",
     "start_time": "2023-11-25T17:23:05.537375900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 19:14:44.818488: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-25 19:14:44.818533: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-25 19:14:44.818623: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-25 19:14:44.868121: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # For data manipulation\n",
    "import numpy as np  # For numerical operations\n",
    "from sklearn.model_selection import train_test_split  # To split the dataset into training and testing sets\n",
    "from sklearn.preprocessing import LabelEncoder  # For converting genre labels from strings to integers\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer  # From Hugging Face transformers\n",
    "import tensorflow as tf  # TensorFlow library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:23:10.928417100Z",
     "start_time": "2023-11-25T17:23:10.926911400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "MODEL_NAME = \"DeepPavlov/rubert-base-cased\"  # Name of the pre-trained RuBERT model\n",
    "MAX_LENGTH = 150  # Maximum length of tokens for each text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:23:17.465560400Z",
     "start_time": "2023-11-25T17:23:10.929423300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "df = pd.read_csv(\"../ArchiveProcessor/dataset.csv\")  # Load the CSV file into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:23:17.604332100Z",
     "start_time": "2023-11-25T17:23:17.497663700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# drop all non-string records, unclear where they are coming from\n",
    "df = df[df.apply(lambda row: isinstance(row['body'], str) and isinstance(row['genre'], str), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:23:17.612850200Z",
     "start_time": "2023-11-25T17:23:17.604332100Z"
    }
   },
   "outputs": [],
   "source": [
    "df['is_sf'] = df['genre'].apply(lambda genres: any(genre.startswith('sf') for genre in genres.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:23:17.625875300Z",
     "start_time": "2023-11-25T17:23:17.614166400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>genre</th>\n",
       "      <th>is_sf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>– сдавленно сказал Ром, застыв на полусогнутых...</td>\n",
       "      <td>sf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>что куда-то запропастился паяльник. Жена у тел...</td>\n",
       "      <td>sf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>настежь окно совсем не спасало. По улице гонял...</td>\n",
       "      <td>sf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>силы и обреченно перетекал в душный вечер, за ...</td>\n",
       "      <td>sf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>осела на ягоды земляники у обочины, просеялась...</td>\n",
       "      <td>sf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32311</th>\n",
       "      <td>остаться в живых? Вопрос философский, не так л...</td>\n",
       "      <td>sf_fantasy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32312</th>\n",
       "      <td>рассказа, в котором отсутствует половина текст...</td>\n",
       "      <td>sf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32313</th>\n",
       "      <td>сенаторы перестают отвечать квалификационным т...</td>\n",
       "      <td>sf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32314</th>\n",
       "      <td>FB2 by Sclex 1.1 — вычитка ошибок by Sclex 1.2...</td>\n",
       "      <td>sf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32315</th>\n",
       "      <td>мир устроен совсем не так, как полагают те, кт...</td>\n",
       "      <td>sf_fantasy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32312 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body       genre  is_sf\n",
       "0      – сдавленно сказал Ром, застыв на полусогнутых...          sf   True\n",
       "1      что куда-то запропастился паяльник. Жена у тел...          sf   True\n",
       "2      настежь окно совсем не спасало. По улице гонял...          sf   True\n",
       "3      силы и обреченно перетекал в душный вечер, за ...          sf   True\n",
       "4      осела на ягоды земляники у обочины, просеялась...          sf   True\n",
       "...                                                  ...         ...    ...\n",
       "32311  остаться в живых? Вопрос философский, не так л...  sf_fantasy   True\n",
       "32312  рассказа, в котором отсутствует половина текст...          sf   True\n",
       "32313  сенаторы перестают отвечать квалификационным т...          sf   True\n",
       "32314  FB2 by Sclex 1.1 — вычитка ошибок by Sclex 1.2...          sf   True\n",
       "32315  мир устроен совсем не так, как полагают те, кт...  sf_fantasy   True\n",
       "\n",
       "[32312 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:23:17.718643Z",
     "start_time": "2023-11-25T17:23:17.627552400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Label Encoding for genres\n",
    "label_encoder = LabelEncoder()  # Initialize the LabelEncoder\n",
    "df['labels'] = label_encoder.fit_transform(df['is_sf'])  # Convert genre strings to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:23:17.738225Z",
     "start_time": "2023-11-25T17:23:17.686817900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>genre</th>\n",
       "      <th>is_sf</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>всех их объединяет одна тема – тема «маленьког...</td>\n",
       "      <td>russian_contemporary</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>художественная и вместе с тем строго документи...</td>\n",
       "      <td>prose_history</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>что не все в жизни меняется с течением времени...</td>\n",
       "      <td>prose_contemporary,religion_rel</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>этот глупец, мало зная, с кем он имеет дело, и...</td>\n",
       "      <td>adv_history</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>нет. Но, быть может, эти два романа не совсем ...</td>\n",
       "      <td>prose_contemporary</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32304</th>\n",
       "      <td>тех, кто смело бросает вызов судьбе. Скажете, ...</td>\n",
       "      <td>love_contemporary</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32305</th>\n",
       "      <td>перо&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Глава 1&lt;/p&gt; Когда, наконе...</td>\n",
       "      <td>det_classic</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32306</th>\n",
       "      <td>армия исполнила свой долг сполна — отрезанные ...</td>\n",
       "      <td>sci_history,nonf_biography</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32307</th>\n",
       "      <td>то время как юные король и королева Северных ц...</td>\n",
       "      <td>child_tale</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32309</th>\n",
       "      <td>обречены на смерть. Они пришли убить десятки м...</td>\n",
       "      <td>sci_history</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22438 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body  \\\n",
       "25     всех их объединяет одна тема – тема «маленьког...   \n",
       "27     художественная и вместе с тем строго документи...   \n",
       "29     что не все в жизни меняется с течением времени...   \n",
       "36     этот глупец, мало зная, с кем он имеет дело, и...   \n",
       "37     нет. Но, быть может, эти два романа не совсем ...   \n",
       "...                                                  ...   \n",
       "32304  тех, кто смело бросает вызов судьбе. Скажете, ...   \n",
       "32305  перо</strong></p> <p>Глава 1</p> Когда, наконе...   \n",
       "32306  армия исполнила свой долг сполна — отрезанные ...   \n",
       "32307  то время как юные король и королева Северных ц...   \n",
       "32309  обречены на смерть. Они пришли убить десятки м...   \n",
       "\n",
       "                                 genre  is_sf  labels  \n",
       "25                russian_contemporary  False       0  \n",
       "27                       prose_history  False       0  \n",
       "29     prose_contemporary,religion_rel  False       0  \n",
       "36                         adv_history  False       0  \n",
       "37                  prose_contemporary  False       0  \n",
       "...                                ...    ...     ...  \n",
       "32304                love_contemporary  False       0  \n",
       "32305                      det_classic  False       0  \n",
       "32306       sci_history,nonf_biography  False       0  \n",
       "32307                       child_tale  False       0  \n",
       "32309                      sci_history  False       0  \n",
       "\n",
       "[22438 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['labels'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:23:17.738745Z",
     "start_time": "2023-11-25T17:23:17.686817900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['body'], df['labels'], test_size=0.2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:23:18.082986Z",
     "start_time": "2023-11-25T17:23:17.686817900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)  # Load the tokenizer for RuBERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:23:18.146291100Z",
     "start_time": "2023-11-25T17:23:18.082986Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize(texts):\n",
    "    return tokenizer(texts, padding='max_length', truncation=True, max_length=MAX_LENGTH, return_tensors='tf')  # Tokenize the texts and convert to TensorFlow tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:23:59.079784900Z",
     "start_time": "2023-11-25T17:23:18.126725500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 19:15:13.864222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-25 19:15:13.887195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-25 19:15:13.887251: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-25 19:15:13.890897: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-25 19:15:13.890936: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-25 19:15:13.890957: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-25 19:15:16.995772: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-25 19:15:16.996014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-25 19:15:16.996024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-11-25 19:15:16.996104: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-25 19:15:16.996479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5397 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:26:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Tokenize data\n",
    "train_encodings = tokenize(train_texts.tolist())  # Tokenize training texts\n",
    "val_encodings = tokenize(val_texts.tolist())  # Tokenize validation texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:23:59.181542200Z",
     "start_time": "2023-11-25T17:23:59.178544100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert labels to TensorFlow format\n",
    "train_labels = tf.convert_to_tensor(train_labels)  # Convert training labels to TensorFlow tensors\n",
    "val_labels = tf.convert_to_tensor(val_labels)  # Convert validation labels to TensorFlow tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:24:04.100020600Z",
     "start_time": "2023-11-25T17:23:59.188614900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 19:15:29.374773: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-25 19:15:31.483856: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 367248384 exceeds 10% of free system memory.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load RuBERT model\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(MODEL_NAME, from_pt=True, num_labels=len(label_encoder.classes_))  # Load RuBERT model with a classification head for the number of genres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:24:04.131041800Z",
     "start_time": "2023-11-25T17:24:04.108909900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)  # Define the optimizer (Adam) with a specific learning rate\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # Define the loss function\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])  # Compile the model with the optimizer, loss function, and accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:25:01.821687500Z",
     "start_time": "2023-11-25T17:24:51.501612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 19:15:48.258316: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c2936260e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-25 19:15:48.258347: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "2023-11-25 19:15:48.275931: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-25 19:15:48.454223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-25 19:15:48.509399: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1616/1616 [==============================] - 670s 400ms/step - loss: 0.3594 - accuracy: 0.8436 - val_loss: 0.2702 - val_accuracy: 0.8870\n",
      "Epoch 2/12\n",
      "1616/1616 [==============================] - 721s 446ms/step - loss: 0.1567 - accuracy: 0.9430 - val_loss: 0.3129 - val_accuracy: 0.8843\n",
      "Epoch 3/12\n",
      " 345/1616 [=====>........................] - ETA: 15:07 - loss: 0.0479 - accuracy: 0.9882"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(\n",
    "    {'input_ids': train_encodings['input_ids'], 'attention_mask': train_encodings['attention_mask']},  # Provide training inputs and attention masks\n",
    "    train_labels,  # Provide training labels\n",
    "    validation_data=({'input_ids': val_encodings['input_ids'], 'attention_mask': val_encodings['attention_mask']}, val_labels),  # Provide validation data\n",
    "    batch_size=16,  # Set batch size\n",
    "    epochs=8  # Set number of epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"rubart-flibusta-genres.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files := []string{\"753030.fb2\", \"753029.fb2\", \"752121.fb2\", \"497148.fb2\", \"501398.fb2\", \"752122.fb2\", \"752120.fb2\", \"552329.fb2\", \"753031.fb2\", \"753032.fb2\", \"755720.fb2\", \"644955.fb2\", \"755721.fb2\", \"710622.fb2\", \"711519.fb2\", \"752119.fb2\", \"753028.fb2\", \"755719.fb2\", \"532471.fb2\", \"450323.fb2\", \"450324.fb2\", \"450325.fb2\", \"553516.fb2\", \"556597.fb2\", \"636576.fb2\", \"450327.fb2\", \"619971.fb2\", \"582607.fb2\", \"693349.fb2\", \"693361.fb2\", \"693346.fb2\", \"477565.fb2\", \"476978.fb2\", \"475108.fb2\", \"693348.fb2\", \"478622.fb2\", \"693359.fb2\", \"693344.fb2\", \"693347.fb2\", \"743384.fb2\", \"741717.fb2\", \"590118.fb2\", \"554672.fb2\", \"554770.fb2\", \"554769.fb2\", \"566760.fb2\", \"588453.fb2\", \"648325.fb2\", \"533343.fb2\", \"591540.fb2\", \"608475.fb2\", \"552981.fb2\", \"539817.fb2\", \"552979.fb2\", \"622698.fb2\", \"664507.fb2\", \"556768.fb2\", \"564146.fb2\", \"577584.fb2\", \"599185.fb2\", \"616366.fb2\", \"617347.fb2\", \"637845.fb2\", \"648854.fb2\", \"691559.fb2\", \"754783.fb2\", \"548574.fb2\", \"525064.fb2\", \"564339.fb2\", \"586199.fb2\", \"622456.fb2\", \"657391.fb2\", \"730122.fb2\", \"577776.fb2\", \"600436.fb2\", \"600437.fb2\", \"601422.fb2\", \"609214.fb2\", \"609585.fb2\", \"623736.fb2\", \"630100.fb2\", \"660951.fb2\", \"678314.fb2\", \"678312.fb2\", \"706500.fb2\", \"740257.fb2\", \"583533.fb2\", \"582971.fb2\", \"585998.fb2\", \"588150.fb2\", \"591195.fb2\", \"597454.fb2\", \"602185.fb2\", \"603839.fb2\", \"606680.fb2\", \"616633.fb2\", \"637499.fb2\", \"676093.fb2\", \"600900.fb2\", \"616092.fb2\", \"608919.fb2\", \"622817.fb2\", \"634955.fb2\", \"643862.fb2\", \"750497.fb2\", \"665066.fb2\", \"665068.fb2\", \"613855.fb2\", \"665154.fb2\", \"665155.fb2\", \"665210.fb2\", \"665069.fb2\", \"665052.fb2\", \"665153.fb2\", \"665209.fb2\", \"640360.fb2\", \"660091.fb2\", \"647975.fb2\", \"692823.fb2\", \"693301.fb2\", \"726412.fb2\", \"726413.fb2\", \"695574.fb2\", \"676143.fb2\", \"693509.fb2\", \"676873.fb2\", \"693510.fb2\", \"711465.fb2\", \"733035.fb2\", \"701371.fb2\", \"740051.fb2\", \"743577.fb2\", \"692730.fb2\", \"692731.fb2\", \"703519.fb2\", \"708175.fb2\", \"710418.fb2\", \"711534.fb2\", \"722711.fb2\", \"724275.fb2\", \"732302.fb2\", \"735681.fb2\", \"747817.fb2\", \"750426.fb2\", \"754174.fb2\", \"754194.fb2\", \"732545.fb2\", \"746165.fb2\", \"732270.fb2\", \"732269.fb2\", \"730317.fb2\", \"732268.fb2\", \"743387.fb2\", \"743386.fb2\", \"758399.fb2\", \"707015.fb2\", \"713278.fb2\", \"726235.fb2\", \"746408.fb2\", \"746409.fb2\", \"750064.fb2\", \"749724.fb2\", \"756178.fb2\"}\n"
     ]
    }
   ],
   "source": [
    "numbers = [\n",
    "    753030, 753029, 752121, 497148, 501398, 752122, 752120, 552329, 753031, 753032, 755720, 644955, 755721, 710622,\n",
    "    711519, 752119, 753028, 755719, 532471, 450323, 450324, 450325, 553516, 556597, 636576, 450327, 619971, 582607,\n",
    "    693349, 693361, 693346, 477565, 476978, 475108, 693348, 478622, 693359, 693344, 693347, 743384, 741717, 590118,\n",
    "    554672, 554770, 554769, 566760, 588453, 648325, 533343, 591540, 608475, 552981, 539817, 552979, 622698, 664507,\n",
    "    556768, 564146, 577584, 599185, 616366, 617347, 637845, 648854, 691559, 754783, 548574, 525064, 564339, 586199,\n",
    "    622456, 657391, 730122, 577776, 600436, 600437, 601422, 609214, 609585, 623736, 630100, 660951, 678314, 678312,\n",
    "    706500, 740257, 583533, 582971, 585998, 588150, 591195, 597454, 602185, 603839, 606680, 616633, 637499, 676093,\n",
    "    600900, 616092, 608919, 622817, 634955, 643862, 750497, 665066, 665068, 613855, 665154, 665155, 665210, 665069,\n",
    "    665052, 665153, 665209, 640360, 660091, 647975, 692823, 693301, 726412, 726413, 695574, 676143, 693509, 676873,\n",
    "    693510, 711465, 733035, 701371, 740051, 743577, 692730, 692731, 703519, 708175, 710418, 711534, 722711, 724275,\n",
    "    732302, 735681, 747817, 750426, 754174, 754194, 732545, 746165, 732270, 732269, 730317, 732268, 743387, 743386,\n",
    "    758399, 707015, 713278, 726235, 746408, 746409, 750064, 749724, 756178\n",
    "]\n",
    "\n",
    "# Convert each number to a string and append \".fb2\"\n",
    "file_names = [f\"\\\"{num}.fb2\\\"\" for num in numbers]\n",
    "\n",
    "# Joining the list into a single string for display\n",
    "formatted_list = \", \".join(file_names)\n",
    "print(\"files := []string{\" + formatted_list + \"}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
